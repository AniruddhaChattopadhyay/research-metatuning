{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from litellm import completion\n",
    "import litellm\n",
    "import os\n",
    "litellm.enable_json_schema_validation = True\n",
    "litellm.set_verbose = True\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "import json\n",
    "from litellm import ModelResponse\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# df = pd.read_json(\"hf://datasets/HuggingFaceH4/MATH-500/test.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "df = pd.read_csv('50 rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>problem</th>\n",
       "      <th>solution</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>level</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>llm_raw_response</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Convert the point $(0,3)$ in rectangular coord...</td>\n",
       "      <td>We have that $r = \\sqrt{0^2 + 3^2} = 3.$  Also...</td>\n",
       "      <td>\\left( 3, \\frac{\\pi}{2} \\right)</td>\n",
       "      <td>Precalculus</td>\n",
       "      <td>2</td>\n",
       "      <td>test/precalculus/807.json</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I need to convert the point ...</td>\n",
       "      <td>The point $(0,3)$ in rectangular coordinates c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Define\\n\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2...</td>\n",
       "      <td>We count the number of times $\\frac{1}{n^3}$ a...</td>\n",
       "      <td>p - q</td>\n",
       "      <td>Intermediate Algebra</td>\n",
       "      <td>5</td>\n",
       "      <td>test/intermediate_algebra/1994.json</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I have this problem where I ...</td>\n",
       "      <td>The given double sum can be rewritten by consi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            problem  \\\n",
       "0           0  Convert the point $(0,3)$ in rectangular coord...   \n",
       "1           1  Define\\n\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2...   \n",
       "\n",
       "                                            solution  \\\n",
       "0  We have that $r = \\sqrt{0^2 + 3^2} = 3.$  Also...   \n",
       "1  We count the number of times $\\frac{1}{n^3}$ a...   \n",
       "\n",
       "                            answer               subject  level  \\\n",
       "0  \\left( 3, \\frac{\\pi}{2} \\right)           Precalculus      2   \n",
       "1                            p - q  Intermediate Algebra      5   \n",
       "\n",
       "                             unique_id  \\\n",
       "0            test/precalculus/807.json   \n",
       "1  test/intermediate_algebra/1994.json   \n",
       "\n",
       "                                    llm_raw_response  \\\n",
       "0  <think>\\nOkay, so I need to convert the point ...   \n",
       "1  <think>\\nOkay, so I have this problem where I ...   \n",
       "\n",
       "                                          llm_answer is_correct  \n",
       "0  The point $(0,3)$ in rectangular coordinates c...       True  \n",
       "1  The given double sum can be rewritten by consi...       True  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\\\theta),$ where $r > 0$ and $0 \\\\le \\\\theta < 2 \\\\pi.$'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "class Answer(BaseModel):\n",
    "  reasoning: str\n",
    "  answer: str\n",
    "\n",
    "class AnswerCorrectness(BaseModel):\n",
    "  correct:bool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response: ChatResponse = chat(model='erwan2/DeepSeek-R1-Distill-Qwen-7B', messages=[\n",
    "#             {\n",
    "#                 'role': 'system',\n",
    "#                 'content': '''Be a helpful assistant.\n",
    "#                 You need to just give me the final answer and no other text. Don't tell the steps. Just give the final output. \n",
    "                \n",
    "#                 example:\n",
    "#                 user query: What is the area of a rectangle with length 3cm and breadth 4cm. \n",
    "#                 assistant output: area is 12 cm squared.\n",
    "#                 ''',\n",
    "#             },\n",
    "#             {\n",
    "#                 'role': 'user',\n",
    "#                 'content': df.loc[0,'problem'],\n",
    "#             }],\n",
    "#         )\n",
    "# answer_content = response['message']['content']\n",
    "# thinking = answer_content[answer_content.find(\"<think>\") + 7:answer_content.find(\"</think>\")].strip()\n",
    "# final_answer = answer_content[answer_content.find(\"</think>\") + 8:].strip()\n",
    "# answer_json = {\n",
    "#     \"reasoning\": thinking,\n",
    "#     \"answer\": final_answer\n",
    "# }\n",
    "# answer_obj = Answer.model_validate_json(json.dumps(answer_json))\n",
    "# answer = answer_obj.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_math_problems(df, start_idx=0, end_idx=20):\n",
    "    for idx in range(start_idx, min(len(df), end_idx + 1)):\n",
    "        response:ChatResponse = chat(model='erwan2/DeepSeek-R1-Distill-Qwen-7B', messages=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': '''Be a helpful assistant.\n",
    "                You need to just give me the final answer and no other text. Don't tell the steps. Just give the final output. \n",
    "                \n",
    "                example:\n",
    "                user query: What is the area of a rectangle with length 3cm and breadth 4cm. \n",
    "                assistant output: area is 12 cm squared.\n",
    "                ''',\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': df.iloc[idx]['problem'],\n",
    "            }],\n",
    "        )\n",
    "        answer_content = response['message']['content']\n",
    "        thinking = answer_content[answer_content.find(\"<think>\") + 7:answer_content.find(\"</think>\")].strip()\n",
    "        final_answer = answer_content[answer_content.find(\"</think>\") + 8:].strip()\n",
    "        answer_json = {\n",
    "            \"reasoning\": thinking,\n",
    "            \"answer\": final_answer\n",
    "        }\n",
    "        answer_obj = Answer.model_validate_json(json.dumps(answer_json))\n",
    "        answer = answer_obj.answer\n",
    "\n",
    "        response = completion(model='gpt-4o', messages=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': '''You are an intellegent maths professor. I will give you 2 answers. \n",
    "                    One Model answer and one student answer. You whether the answer is right or wrong.Return a json with key are correct and value as True or False depeding on your evaluation''',\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Model Answer : {df.iloc[idx][\"answer\"]}, Student Answer : {answer}',\n",
    "            },\n",
    "        ], \n",
    "        response_format=AnswerCorrectness)\n",
    "        \n",
    "        answer_correctness = response.choices[0]['message']['content']\n",
    "        answer_correctness_obj = AnswerCorrectness.model_validate_json(answer_correctness)\n",
    "        \n",
    "        df.at[idx, 'llm_raw_response'] = answer_content\n",
    "        df.at[idx, 'llm_answer'] = answer\n",
    "        df.at[idx, 'is_correct'] = answer_correctness_obj.correct\n",
    "        \n",
    "        print(f\"Processed row {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:48:12 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07r3HIkm3aXWOTfFvNnsUieJLK8N\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":false}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739369893, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 471, \"total_tokens\": 477, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:48:34 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07rPrDMDGFJl08arkBR7BxvrH6q7\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739369915, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 169, \"total_tokens\": 175, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:48:48 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07rcAzQPUFIIIwWIJGrgGqi8VlOl\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739369928, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 128, \"total_tokens\": 134, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:50:46 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07tXnWkylPZQoEOyvRfY4GqAjiLZ\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739370047, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 375, \"total_tokens\": 381, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:51:01 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07tmodK12daTtned8lBXDqLKLgMk\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739370062, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 181, \"total_tokens\": 187, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:51:17 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07u2XmMxiwnTk3Az5o5VSaeTyPL6\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739370078, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 143, \"total_tokens\": 149, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:51:38 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07uNmHmz22RDbHrl7WtJ28ocSpVJ\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739370099, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_4691090a87\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 124, \"total_tokens\": 130, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:53:57 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07wb8CaOulAZ3KBLXwyYcuPvH5KZ\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":false}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739370237, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 130, \"total_tokens\": 136, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 50\n"
     ]
    }
   ],
   "source": [
    "process_math_problems(df,start_idx=43,end_idx=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"50 rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_messages(df, start_idx=0, num_rows=20):\n",
    "    end_idx = min(start_idx + num_rows, len(df))\n",
    "    messages = [{\n",
    "                'role': 'system',\n",
    "                'content': '''Be a helpful assistant.\n",
    "                You need to just give me the final answer and no other text. Don't tell the steps. Just give the final output. \n",
    "                \n",
    "                example:\n",
    "                user query: What is the area of a rectangle with length 3cm and breadth 4cm. \n",
    "                assistant output: area is 12 cm squared.'''\n",
    "            }]\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        row = df.iloc[idx]\n",
    "        \n",
    "        # Base messages that are common for all examples\n",
    "        messages.extend([\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': row['problem']\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': row['llm_raw_response']\n",
    "            }\n",
    "        ])\n",
    "        \n",
    "        # Add feedback based on correctness\n",
    "        if not row['is_correct']:\n",
    "            messages.append({\n",
    "                'role': 'user',\n",
    "                'content': f\"Let me correct this. The right answer is {row['answer']}. Let's understand the solution: {row['solution']}\"\n",
    "            })\n",
    "        else:\n",
    "            messages.append({\n",
    "                'role': 'user',\n",
    "                'content': \"Good job! Your reasoning and answer are correct!\"\n",
    "            })\n",
    "        messages.append({\n",
    "            'role': 'assistant',\n",
    "            'content': \"Understood. I will keep this in mind\"\n",
    "        })\n",
    "            \n",
    "       \n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = generate_training_messages(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_process_math_problems_te(df, start_idx=20, end_idx=30):\n",
    "    for idx in range(start_idx, min(len(df), end_idx + 1)):\n",
    "        messages = training_data + [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': '''Be a helpful assistant.\n",
    "                You need to just give me the final answer and no other text. Don't tell the steps. Just give the final output. \n",
    "                \n",
    "                example:\n",
    "                user query: What is the area of a rectangle with length 3cm and breadth 4cm. \n",
    "                assistant output: area is 12 cm squared.''',\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': df.iloc[idx]['problem'],\n",
    "            }]\n",
    "        \n",
    "        response:ChatResponse = chat(model='erwan2/DeepSeek-R1-Distill-Qwen-7B', \n",
    "                                      messages=messages, options={\"num_ctx\": 20000})\n",
    "        answer_content = response['message']['content']\n",
    "        thinking = answer_content[answer_content.find(\"<think>\") + 7:answer_content.find(\"</think>\")].strip()\n",
    "        final_answer = answer_content[answer_content.find(\"</think>\") + 8:].strip()\n",
    "        answer_json = {\n",
    "            \"reasoning\": thinking,\n",
    "            \"answer\": final_answer\n",
    "        }\n",
    "        answer_obj = Answer.model_validate_json(json.dumps(answer_json))\n",
    "        answer = answer_obj.answer\n",
    "\n",
    "        response = completion(model='gpt-4o', messages=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': '''You are an intellegent maths professor. I will give you 2 answers. \n",
    "                    One Model answer and one student answer. You whether the answer is right or wrong.Return a json with key are correct and value as True or False depeding on your evaluation''',\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Model Answer : {df.iloc[idx][\"answer\"]}, Student Answer : {answer}',\n",
    "            },\n",
    "        ], \n",
    "        response_format=AnswerCorrectness)\n",
    "        \n",
    "        answer_correctness = response.choices[0]['message']['content']\n",
    "        answer_correctness_obj = AnswerCorrectness.model_validate_json(answer_correctness)\n",
    "        \n",
    "        df.at[idx, 'llm_raw_response_test'] = answer_content\n",
    "        df.at[idx, 'llm_answer_test'] = answer\n",
    "        df.at[idx, 'is_correct_test'] = answer_correctness_obj.correct\n",
    "        \n",
    "        print(f\"Processed row {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:16:25 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08IMbqhJeHTkXiuPLZ8COKmAu38A\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739371586, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 264, \"total_tokens\": 270, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:22:07 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08NtSdSibgmrCFjueq98gGefkxi6\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739371929, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_4691090a87\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 3512, \"total_tokens\": 3518, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:27:10 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08Sl9Ld7FTXYvpEthP9m8mvdwynk\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":false}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739372231, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 134, \"total_tokens\": 140, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:30:47 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08WGpviJX89dg2yVMT0GK6xZzcNY\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739372448, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 485, \"total_tokens\": 491, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:31:58 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08XPSroUIGWgAd8w3F9056xIRyGa\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":false}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739372519, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 148, \"total_tokens\": 154, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:35:16 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08aaUguEuX6YDzIHN5aByx05ub07\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739372716, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 569, \"total_tokens\": 575, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:50:18 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08p9MyMzPxVHVHq5MZfmtjb8GnJi\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739373619, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 117, \"total_tokens\": 123, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:53:51 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08saCiKLgehhe0jglMAQkiqDO97h\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":false}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739373832, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_4691090a87\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 257, \"total_tokens\": 263, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:56:28 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08v6N5n45qNPrJv6R1TKuJaZgYf6\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739373988, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 326, \"total_tokens\": 332, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m20:57:40 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08wHb5Rl0a3QyD5RhLEyx8rfrW3u\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739374061, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 351, \"total_tokens\": 357, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m21:00:20 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B08yrdh9XUbVYxlrlbYJAqg7ep6B7\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739374221, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_4691090a87\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 126, \"total_tokens\": 132, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 30\n"
     ]
    }
   ],
   "source": [
    "test_process_math_problems_te(df,start_idx=20,end_idx=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('first 50 test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.iloc[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_correct\n",
       "True     9\n",
       "False    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['is_correct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_correct_test\n",
       "True     7\n",
       "False    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['is_correct_test'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
