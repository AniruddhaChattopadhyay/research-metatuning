{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from litellm import completion\n",
    "import litellm\n",
    "import os\n",
    "litellm.enable_json_schema_validation = True\n",
    "litellm.set_verbose = True\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "import json\n",
    "from litellm import ModelResponse\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# df = pd.read_json(\"hf://datasets/HuggingFaceH4/MATH-500/test.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "df = pd.read_csv('50 rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>problem</th>\n",
       "      <th>solution</th>\n",
       "      <th>answer</th>\n",
       "      <th>subject</th>\n",
       "      <th>level</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>llm_raw_response</th>\n",
       "      <th>llm_answer</th>\n",
       "      <th>is_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Convert the point $(0,3)$ in rectangular coord...</td>\n",
       "      <td>We have that $r = \\sqrt{0^2 + 3^2} = 3.$  Also...</td>\n",
       "      <td>\\left( 3, \\frac{\\pi}{2} \\right)</td>\n",
       "      <td>Precalculus</td>\n",
       "      <td>2</td>\n",
       "      <td>test/precalculus/807.json</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I need to convert the point ...</td>\n",
       "      <td>The point $(0,3)$ in rectangular coordinates c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Define\\n\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2...</td>\n",
       "      <td>We count the number of times $\\frac{1}{n^3}$ a...</td>\n",
       "      <td>p - q</td>\n",
       "      <td>Intermediate Algebra</td>\n",
       "      <td>5</td>\n",
       "      <td>test/intermediate_algebra/1994.json</td>\n",
       "      <td>&lt;think&gt;\\nOkay, so I have this problem where I ...</td>\n",
       "      <td>The given double sum can be rewritten by consi...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "\n",
       "                                             problem  \\\n",
       "0  Convert the point $(0,3)$ in rectangular coord...   \n",
       "1  Define\\n\\[p = \\sum_{k = 1}^\\infty \\frac{1}{k^2...   \n",
       "\n",
       "                                            solution  \\\n",
       "0  We have that $r = \\sqrt{0^2 + 3^2} = 3.$  Also...   \n",
       "1  We count the number of times $\\frac{1}{n^3}$ a...   \n",
       "\n",
       "                            answer               subject  level  \\\n",
       "0  \\left( 3, \\frac{\\pi}{2} \\right)           Precalculus      2   \n",
       "1                            p - q  Intermediate Algebra      5   \n",
       "\n",
       "                             unique_id  \\\n",
       "0            test/precalculus/807.json   \n",
       "1  test/intermediate_algebra/1994.json   \n",
       "\n",
       "                                    llm_raw_response  \\\n",
       "0  <think>\\nOkay, so I need to convert the point ...   \n",
       "1  <think>\\nOkay, so I have this problem where I ...   \n",
       "\n",
       "                                          llm_answer is_correct  \n",
       "0  The point $(0,3)$ in rectangular coordinates c...       True  \n",
       "1  The given double sum can be rewritten by consi...       True  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Convert the point $(0,3)$ in rectangular coordinates to polar coordinates.  Enter your answer in the form $(r,\\\\theta),$ where $r > 0$ and $0 \\\\le \\\\theta < 2 \\\\pi.$'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[0,'problem']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "class Answer(BaseModel):\n",
    "  reasoning: str\n",
    "  answer: str\n",
    "\n",
    "class AnswerCorrectness(BaseModel):\n",
    "  correct:bool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response: ChatResponse = chat(model='erwan2/DeepSeek-R1-Distill-Qwen-7B', messages=[\n",
    "#             {\n",
    "#                 'role': 'system',\n",
    "#                 'content': '''Be a helpful assistant.\n",
    "#                 You need to just give me the final answer and no other text. Don't tell the steps. Just give the final output. \n",
    "                \n",
    "#                 example:\n",
    "#                 user query: What is the area of a rectangle with length 3cm and breadth 4cm. \n",
    "#                 assistant output: area is 12 cm squared.\n",
    "#                 ''',\n",
    "#             },\n",
    "#             {\n",
    "#                 'role': 'user',\n",
    "#                 'content': df.loc[0,'problem'],\n",
    "#             }],\n",
    "#         )\n",
    "# answer_content = response['message']['content']\n",
    "# thinking = answer_content[answer_content.find(\"<think>\") + 7:answer_content.find(\"</think>\")].strip()\n",
    "# final_answer = answer_content[answer_content.find(\"</think>\") + 8:].strip()\n",
    "# answer_json = {\n",
    "#     \"reasoning\": thinking,\n",
    "#     \"answer\": final_answer\n",
    "# }\n",
    "# answer_obj = Answer.model_validate_json(json.dumps(answer_json))\n",
    "# answer = answer_obj.answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_math_problems(df, start_idx=0, end_idx=20):\n",
    "    for idx in range(start_idx, min(len(df), end_idx + 1)):\n",
    "        response:ChatResponse = chat(model='erwan2/DeepSeek-R1-Distill-Qwen-7B', messages=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': '''Be a helpful assistant.\n",
    "                You need to just give me the final answer and no other text. Don't tell the steps. Just give the final output. \n",
    "                \n",
    "                example:\n",
    "                user query: What is the area of a rectangle with length 3cm and breadth 4cm. \n",
    "                assistant output: area is 12 cm squared.\n",
    "                ''',\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': df.iloc[idx]['problem'],\n",
    "            }],\n",
    "        )\n",
    "        answer_content = response['message']['content']\n",
    "        thinking = answer_content[answer_content.find(\"<think>\") + 7:answer_content.find(\"</think>\")].strip()\n",
    "        final_answer = answer_content[answer_content.find(\"</think>\") + 8:].strip()\n",
    "        answer_json = {\n",
    "            \"reasoning\": thinking,\n",
    "            \"answer\": final_answer\n",
    "        }\n",
    "        answer_obj = Answer.model_validate_json(json.dumps(answer_json))\n",
    "        answer = answer_obj.answer\n",
    "\n",
    "        response = completion(model='gpt-4o', messages=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': '''You are an intellegent maths professor. I will give you 2 answers. \n",
    "                    One Model answer and one student answer. You whether the answer is right or wrong.Return a json with key are correct and value as True or False depeding on your evaluation''',\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Model Answer : {df.iloc[idx][\"answer\"]}, Student Answer : {answer}',\n",
    "            },\n",
    "        ], \n",
    "        response_format=AnswerCorrectness)\n",
    "        \n",
    "        answer_correctness = response.choices[0]['message']['content']\n",
    "        answer_correctness_obj = AnswerCorrectness.model_validate_json(answer_correctness)\n",
    "        \n",
    "        df.at[idx, 'llm_raw_response'] = answer_content\n",
    "        df.at[idx, 'llm_answer'] = answer\n",
    "        df.at[idx, 'is_correct'] = answer_correctness_obj.correct\n",
    "        \n",
    "        print(f\"Processed row {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:48:12 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07r3HIkm3aXWOTfFvNnsUieJLK8N\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":false}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739369893, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 471, \"total_tokens\": 477, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:48:34 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07rPrDMDGFJl08arkBR7BxvrH6q7\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739369915, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 169, \"total_tokens\": 175, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:48:48 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07rcAzQPUFIIIwWIJGrgGqi8VlOl\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739369928, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 128, \"total_tokens\": 134, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:50:46 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07tXnWkylPZQoEOyvRfY4GqAjiLZ\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739370047, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 375, \"total_tokens\": 381, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:51:01 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07tmodK12daTtned8lBXDqLKLgMk\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739370062, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 181, \"total_tokens\": 187, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:51:17 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07u2XmMxiwnTk3Az5o5VSaeTyPL6\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739370078, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 143, \"total_tokens\": 149, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:51:38 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07uNmHmz22RDbHrl7WtJ28ocSpVJ\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739370099, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_4691090a87\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 124, \"total_tokens\": 130, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m19:53:57 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B07wb8CaOulAZ3KBLXwyYcuPvH5KZ\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":false}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739370237, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 130, \"total_tokens\": 136, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 50\n"
     ]
    }
   ],
   "source": [
    "process_math_problems(df,start_idx=43,end_idx=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"50 rows.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_messages(df, start_idx=0, num_rows=20):\n",
    "    end_idx = min(start_idx + num_rows, len(df))\n",
    "    messages = [{\n",
    "                'role': 'system',\n",
    "                'content': '''Be a helpful assistant.\n",
    "                You need to just give me the final answer and no other text. Don't tell the steps. Just give the final output. \n",
    "                \n",
    "                example:\n",
    "                user query: What is the area of a rectangle with length 3cm and breadth 4cm. \n",
    "                assistant output: area is 12 cm squared.'''\n",
    "            }]\n",
    "    for idx in range(start_idx, end_idx):\n",
    "        row = df.iloc[idx]\n",
    "        \n",
    "        # Base messages that are common for all examples\n",
    "        messages.extend([\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': row['problem']\n",
    "            },\n",
    "            {\n",
    "                'role': 'assistant',\n",
    "                'content': row['llm_raw_response']\n",
    "            }\n",
    "        ])\n",
    "        \n",
    "        # Add feedback based on correctness\n",
    "        if not row['is_correct']:\n",
    "            messages.append({\n",
    "                'role': 'user',\n",
    "                'content': f\"Let me correct this. The right answer is {row['answer']}. Let's understand the solution: {row['solution']}\"\n",
    "            })\n",
    "        else:\n",
    "            messages.append({\n",
    "                'role': 'user',\n",
    "                'content': \"Good job! Your reasoning and answer are correct!\"\n",
    "            })\n",
    "        messages.append({\n",
    "            'role': 'assistant',\n",
    "            'content': \"Understood. I will keep this in mind\"\n",
    "        })\n",
    "            \n",
    "       \n",
    "    \n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = generate_training_messages(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_process_math_problems_te(df, start_idx=20, end_idx=30):\n",
    "    for idx in range(start_idx, min(len(df), end_idx + 1)):\n",
    "        messages = training_data + [\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': '''Be a helpful assistant.\n",
    "                You need to just give me the final answer and no other text. Don't tell the steps. Just give the final output. \n",
    "                \n",
    "                example:\n",
    "                user query: What is the area of a rectangle with length 3cm and breadth 4cm. \n",
    "                assistant output: area is 12 cm squared.''',\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': df.iloc[idx]['problem'],\n",
    "            }]\n",
    "        \n",
    "        response:ChatResponse = chat(model='erwan2/DeepSeek-R1-Distill-Qwen-7B', \n",
    "                                      messages=messages, options={\"num_ctx\": 20000})\n",
    "        answer_content = response['message']['content']\n",
    "        thinking = answer_content[answer_content.find(\"<think>\") + 7:answer_content.find(\"</think>\")].strip()\n",
    "        final_answer = answer_content[answer_content.find(\"</think>\") + 8:].strip()\n",
    "        answer_json = {\n",
    "            \"reasoning\": thinking,\n",
    "            \"answer\": final_answer\n",
    "        }\n",
    "        answer_obj = Answer.model_validate_json(json.dumps(answer_json))\n",
    "        answer = answer_obj.answer\n",
    "\n",
    "        response = completion(model='gpt-4o', messages=[\n",
    "            {\n",
    "                'role': 'system',\n",
    "                'content': '''You are an intellegent maths professor. I will give you 2 answers. \n",
    "                    One Model answer and one student answer. You whether the answer is right or wrong.Return a json with key are correct and value as True or False depeding on your evaluation''',\n",
    "            },\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': f'Model Answer : {df.iloc[idx][\"answer\"]}, Student Answer : {answer}',\n",
    "            },\n",
    "        ], \n",
    "        response_format=AnswerCorrectness)\n",
    "        \n",
    "        answer_correctness = response.choices[0]['message']['content']\n",
    "        answer_correctness_obj = AnswerCorrectness.model_validate_json(answer_correctness)\n",
    "        \n",
    "        df.at[idx, 'llm_raw_response_test'] = answer_content\n",
    "        df.at[idx, 'llm_answer_test'] = answer\n",
    "        df.at[idx, 'is_correct_test'] = answer_correctness_obj.correct\n",
    "        \n",
    "        print(f\"Processed row {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m02:49:01 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0EQInFmIDsJoP1nUfROGTLnOK9S8\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739395142, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_4691090a87\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 255, \"total_tokens\": 261, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m02:51:30 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0ESg5iL4S3ZlpaxSMJOLL8xtTEOH\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739395290, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_4691090a87\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 426, \"total_tokens\": 432, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m03:24:01 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0EyBx7BIr5yCDzD1brMfpiMh2xY7\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":false}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739397243, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 433, \"total_tokens\": 439, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m03:41:21 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0FEwTlTwIaVyYJMKtxE92GUyVwmc\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739398282, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 621, \"total_tokens\": 627, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m03:44:02 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0FHXwzwITCmyMz7w3dMcQRPjZzRl\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739398443, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 329, \"total_tokens\": 335, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m03:46:52 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0FKH3XsLP1tMwWbwUjLpIeBXscmu\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739398613, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 462, \"total_tokens\": 468, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m03:58:26 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0FVTq5eO613IXbdGbrQKbe6dTxj2\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":false}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739399307, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 1438, \"total_tokens\": 1444, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m04:01:24 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0FYLKmj94pujtEzftDDNE59Tr51V\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739399485, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_4691090a87\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 190, \"total_tokens\": 196, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m04:02:43 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0FZcgppAl4wP4w6Ior9nAF5aaHNs\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739399564, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 278, \"total_tokens\": 284, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m04:03:25 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0FaHQ5M25oPAcJM0KrfJOGgQn52i\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":false}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739399605, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_50cad350e4\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 504, \"total_tokens\": 510, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m04:04:44 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0FbZu0L1QiuZroc7z5uV1PhkBcl6\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739399685, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_4691090a87\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 915, \"total_tokens\": 921, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m04:05:36 - LiteLLM:WARNING\u001b[0m: utils.py:430 - `litellm.set_verbose` is deprecated. Please set `os.environ['LITELLM_LOG'] = 'DEBUG'` for debug logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False\n",
      "Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'schema': {'properties': {'correct': {'title': 'Correct', 'type': 'boolean'}}, 'required': ['correct'], 'title': 'AnswerCorrectness', 'type': 'object', 'additionalProperties': False}, 'name': 'AnswerCorrectness', 'strict': True}}, 'extra_body': {}}\n",
      "RAW RESPONSE:\n",
      "{\"id\": \"chatcmpl-B0FcPpfzRrstcxsNSyq8SdY80Tfm3\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"logprobs\": null, \"message\": {\"content\": \"{\\\"correct\\\":true}\", \"refusal\": null, \"role\": \"assistant\", \"audio\": null, \"function_call\": null, \"tool_calls\": null}}], \"created\": 1739399737, \"model\": \"gpt-4o-2024-08-06\", \"object\": \"chat.completion\", \"service_tier\": \"default\", \"system_fingerprint\": \"fp_4691090a87\", \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 562, \"total_tokens\": 568, \"completion_tokens_details\": {\"accepted_prediction_tokens\": 0, \"audio_tokens\": 0, \"reasoning_tokens\": 0, \"rejected_prediction_tokens\": 0}, \"prompt_tokens_details\": {\"audio_tokens\": 0, \"cached_tokens\": 0}}}\n",
      "\n",
      "\n",
      "Processed row 31\n"
     ]
    }
   ],
   "source": [
    "test_process_math_problems_te(df,start_idx=20,end_idx=31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('first 50 test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.iloc[20:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_correct\n",
       "True     25\n",
       "False     5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['is_correct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_correct_test\n",
       "True     23\n",
       "False     7\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['is_correct_test'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.llms.anthropic import Anthropic\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
